{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(pretrained):\n",
    "    model = Sequential([\n",
    "        pretrained,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer=Adam(),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102041 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "base_path = './combined-real-and-fake-faces/combined-real-vs-fake/'\n",
    "\n",
    "image_gen = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "train_flow = image_gen.flow_from_directory(\n",
    "    base_path + 'train/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen1 = ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "valid_flow = image_gen1.flow_from_directory(\n",
    "    base_path + 'valid/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1024)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,038,529\n",
      "Trainable params: 6,954,881\n",
      "Non-trainable params: 83,648\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densenet = DenseNet121(\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "model = build_model(densenet)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12500/12500 [==============================] - 2649s 211ms/step - loss: 0.6742 - accuracy: 0.5716 - val_loss: 0.6020 - val_accuracy: 0.6781\n",
      "Epoch 2/10\n",
      "12500/12500 [==============================] - 2521s 202ms/step - loss: 0.5165 - accuracy: 0.7455 - val_loss: 0.4899 - val_accuracy: 0.7677\n",
      "Epoch 3/10\n",
      "12500/12500 [==============================] - 2533s 203ms/step - loss: 0.3858 - accuracy: 0.8298 - val_loss: 0.3101 - val_accuracy: 0.8683\n",
      "Epoch 4/10\n",
      "12074/12500 [===========================>..] - ETA: 1:20 - loss: 0.2836 - accuracy: 0.8822"
     ]
    }
   ],
   "source": [
    "train_steps = 100000//batch_size\n",
    "valid_steps = 20000//batch_size\n",
    "\n",
    "history = model.fit(\n",
    "    train_flow,\n",
    "    epochs = 10,\n",
    "    steps_per_epoch =train_steps,\n",
    "    validation_data =valid_flow,\n",
    "    validation_steps = valid_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('densenet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the training and validation loss\n",
    "epochs - list of epoch numbers\n",
    "loss - training loss for each epoch\n",
    "val_loss - validation loss for each epoch\n",
    "\"\"\"\n",
    "def plot_loss(epochs, loss, val_loss):\n",
    "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'orange', label = 'Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "Plot the training and validation accuracy\n",
    "epochs - list of epoch numbers\n",
    "acc - training accuracy for each epoch\n",
    "val_acc - validation accuracy for each epoch\n",
    "\"\"\"\n",
    "def plot_accuracy(epochs, acc, val_acc):\n",
    "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'orange', label = 'Validation accuracy')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(range(1, len(loss) + 1), loss, val_loss)\n",
    "plot_accuracy(range(1, len(loss) + 1), acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_flow = image_gen1.flow_from_directory(\n",
    "    base_path + 'test/',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=1,\n",
    "    shuffle = False,\n",
    "    class_mode='binary'\n",
    ")\n",
    "y_pred = model.predict(test_flow)\n",
    "y_test = test_flow.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
    "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
    "print()\n",
    "print(metrics.classification_report(y_test, y_pred > 0.5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
